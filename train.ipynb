{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1680/3025873521.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import efficientnet_b0\n",
    "from torchvision.models import EfficientNet_B0_Weights\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "class MvtecADDataset(Dataset):\n",
    "    def __init__(self, root_dir, split=\"train\", transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "        \n",
    "        self.image_paths = []\n",
    "        self.mask_paths = []\n",
    "        self.labels = []\n",
    "        self.images = []\n",
    "        \n",
    "        for object_type in tqdm(os.listdir(root_dir)):\n",
    "            object_path = os.path.join(root_dir, object_type)\n",
    "            if not os.path.isdir(object_path):\n",
    "                continue\n",
    "            \n",
    "            if split == \"train\":\n",
    "                train_dir = os.path.join(object_path, \"train\", \"good\")\n",
    "                self.image_paths.extend([os.path.join(train_dir, img) for img in os.listdir(train_dir)])\n",
    "                # self.images.extend([Image.open(os.path.join(train_dir, img)).convert(\"RGB\") for img in os.listdir(train_dir)])\n",
    "                self.labels.extend([0] * len(self.image_paths))\n",
    "                self.mask_paths.extend([None] * len(self.image_paths))\n",
    "\n",
    "            elif split == \"test\":\n",
    "                test_dir = os.path.join(object_path, \"test\")\n",
    "                ground_truth_dir = os.path.join(object_path, \"ground_truth\")\n",
    "                \n",
    "                for defect_type in os.listdir(test_dir):\n",
    "                    defect_dir = os.path.join(test_dir, defect_type)\n",
    "                    for img_name in os.listdir(defect_dir):\n",
    "                        img_path = os.path.join(defect_dir, img_name)\n",
    "                        self.image_paths.append(img_path)\n",
    "                        # self.images.append(Image.open(img_path).convert(\"RGB\"))\n",
    "                        \n",
    "                        if defect_type == \"good\":\n",
    "                            self.labels.append(0)\n",
    "                            self.mask_paths.append(None)\n",
    "                        else:\n",
    "                            self.labels.append(1)\n",
    "                            mask_path = os.path.join(ground_truth_dir, defect_type, img_name)\n",
    "                            self.mask_paths.append(mask_path if os.path.exists(mask_path) else None)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        original_img_size = image.size\n",
    "        mask = None\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        # 마스크 로드 (None일 경우 이미지와 동일한 크기의 0으로 채워진 텐서 생성)\n",
    "        if self.mask_paths[idx] is not None:\n",
    "            mask = Image.open(self.mask_paths[idx]).convert(\"L\")\n",
    "            if self.transform:\n",
    "                mask = self.transform(mask)\n",
    "        else:\n",
    "            # mask가 None일 경우 0으로 채워진 텐서 생성 (이미지와 동일한 크기)\n",
    "            _, width, height = image.shape  # PIL 이미지의 크기 가져오기\n",
    "            mask = torch.zeros((1, height, width), dtype=torch.float32)  # (C, H, W) 형식 유지\n",
    "\n",
    "        return image, mask, label, original_img_size, img_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EfficientNet 기반 Autoencoder 정의\n",
    "class EfficientNetB0Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EfficientNetB0Autoencoder, self).__init__()\n",
    "        # EfficientNet-b0을 encoder로 사용\n",
    "        self.encoder = efficientnet_b0(EfficientNet_B0_Weights.DEFAULT)\n",
    "        \n",
    "        # Decoder 정의\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(1280, 512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Sigmoid(),  # pixel 값을 [0, 1] 범위로 맞추기 위해 사용\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder를 통해 특징 추출\n",
    "        x = self.encoder.features(x)\n",
    "        # Decoder를 통해 재구성\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a16ea20294614af28b1e82d0f223159d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fb8ca84d7464e32900c84c272cebcc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# 데이터 전처리 및 데이터 로더 설정\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = MvtecADDataset(root_dir=\"mvtec_anomaly_detection\", split=\"train\", transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "test_dataset = MvtecADDataset(root_dir=\"mvtec_anomaly_detection\", split=\"test\", transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# 모델 학습 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = EfficientNetB0Autoencoder().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0625fcb708a47fab3094255833b9fe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/227 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.0180\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bc52c42b6f4461eaeb1c64ca27dab5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/227 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Loss: 0.0081\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79a605345d93420299d4e32f5de107c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/227 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Loss: 0.0065\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afb5cf4186a543a58ab47385cfe3c170",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/227 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Loss: 0.0067\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "658b84735682464e81c338f7c1f9be55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/227 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Loss: 0.0058\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "021fa7b02be4425e920877491fb57ae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/227 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Loss: 0.0055\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ac2c0b6d0664507a5c29d0b6f0114e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/227 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Loss: 0.0053\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d4159fc15004ff384d5093b6a3558d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/227 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Loss: 0.0051\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "990158b9f6804b028907087d0b00a213",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/227 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Loss: 0.0050\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db01e6a68152487e89c59e44fb4b2939",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/227 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Loss: 0.0042\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1073797652d1413b94aafe5c0ea06e67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/227 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Loss: 0.0040\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffdc8ed2f26d4e0cb0bcfe10230c6cc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/227 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Loss: 0.0039\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31aa36971f264b8b876bf91cbeae6bad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/227 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Loss: 0.0036\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd0cff0708bb4eafb62a8ff53cf534c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/227 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], Loss: 0.0035\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "286897987ab548919042ed720d4979f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/227 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20], Loss: 0.0033\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd56d585ffa04042af482dfafee76368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/227 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], Loss: 0.0031\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e213ffc7a3e41a98ca4bbc261de4831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/227 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20], Loss: 0.0030\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b305b2b2dd049089e35d1e545b4a75d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/227 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20], Loss: 0.0036\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd102cdfc05b4770bbc8dba3a7ca8a4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/227 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], Loss: 0.0034\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5889df9e1b9744df937d2f35ba05899f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/227 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], Loss: 0.0030\n"
     ]
    }
   ],
   "source": [
    "# 학습 루프\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for images, _, _, _, _ in tqdm(train_loader):\n",
    "        images = images.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, images)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss / len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision.utils import save_image\n",
    "from PIL import Image\n",
    "import tiffile as tiff\n",
    "\n",
    "# Anomaly Map을 저장할 최상위 폴더 경로\n",
    "root_anomaly_map_dir =  \"anomaly_maps/\" + model.__class__.__name__\n",
    "\n",
    "def save_anomaly_map(anomaly_map, image_path, anomaly_root_dir):\n",
    "    \"\"\"\n",
    "    anomaly_map을 원본 이미지와 동일한 폴더 구조로 anomaly_root_dir에 저장합니다.\n",
    "    \n",
    "    Args:\n",
    "        anomaly_map (Tensor): anomaly map 이미지\n",
    "        image_path (str): 원본 이미지 경로\n",
    "        anomaly_root_dir (str): anomaly map의 최상위 폴더 경로\n",
    "    \"\"\"\n",
    "    # 이미지의 파일 경로에서 최상위 디렉토리를 제외한 경로 추출\n",
    "    relative_path = os.path.relpath(image_path, start='mvtec_anomaly_detection')\n",
    "    relative_path = os.path.splitext(relative_path)[0] + '.tiff'\n",
    "    save_path = os.path.join(anomaly_root_dir, relative_path)\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "    \n",
    "    # anomaly map 저장\n",
    "    tiff.imwrite(save_path, anomaly_map)\n",
    "\n",
    "# 테스트 시 anomaly map 저장\n",
    "def test_and_save_anomaly_maps(model, test_loader, device, root_anomaly_map_dir):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, _, _, original_image_size, image_paths) in enumerate(tqdm(test_loader)):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "\n",
    "            # 재구성 오차 기반 anomaly map 생성\n",
    "            anomaly_maps = F.mse_loss(outputs, images, reduction='none').mean(dim=1, keepdim=True)\n",
    "\n",
    "            # 배치의 각 이미지에 대해 anomaly map 저장 \n",
    "            for i in range(images.size(0)):\n",
    "                image_path = image_paths[i]\n",
    "\n",
    "                # original_image_size should be in the format (height, width)\n",
    "                height, width = original_image_size[0][i].item(), original_image_size[1][i].item()\n",
    "                \n",
    "                # Use 'bilinear' for 2D data\n",
    "                # anomaly_map = F.interpolate(anomaly_maps[i].unsqueeze(0), size=(height, width), mode='bilinear', align_corners=False)\n",
    "                \n",
    "                # Convert anomaly_map to (H, W, C) format for saving as an image\n",
    "                anomaly_map = anomaly_maps[i].squeeze().cpu().numpy()\n",
    "                \n",
    "                save_anomaly_map(anomaly_map, image_path, root_anomaly_map_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "769494acd8d943deb926c331067bcc08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_and_save_anomaly_maps(model, test_loader, device, root_anomaly_map_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'model/{model.__class__.__name__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(model_class, state_dict_path):\n",
    "    model = model_class()\n",
    "    model.load_state_dict(torch.load(state_dict_path, weights_only=True))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load(EfficientNetAutoencoder, 'model/efficientb0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
